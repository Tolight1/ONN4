import numpy as np
import matplotlib.pyplot as plt
import itertools
import copy
from tqdm import tqdm
import torch
from torch.utils.data import DataLoader
import torch.nn.functional as F
import torchvision
from torchvision import transforms

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
IMG_SIZE=80
batch_size=64
N_pixels=80
pixel_size = 500e-9
distance = 150e-6
wl = 940e-9
torch.autograd.set_detect_anomaly(True)   #检测反向传播时候出现问题的地方
def filter_digitsXX(dataset, digits=(0, 1)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            filtered_data.append(item)
    return filtered_data
def filter_digitsXY(dataset, digits=(2, 3)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            listitem = list(item)
            if item[1]==3:
                item = list(item)
                item[1] = 1
                item = tuple(item)
            else:
                item = list(item)
                item[1] = 0
                item = tuple(item)
            filtered_data.append(item)
    return filtered_data
def filter_digitsYX(dataset, digits=(4, 5)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            if item[1] in digits:
                if item[1] == 5:
                    item = list(item)
                    item[1] = 1
                    item = tuple(item)
                else:
                    item = list(item)
                    item[1] = 0
                    item = tuple(item)
                filtered_data.append(item)
    return filtered_data
def filter_digitsYY(dataset, digits=(6, 7)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            if item[1] in digits:
                if item[1] == 7:
                    item = list(item)
                    item[1] = 1
                    item = tuple(item)
                else:
                    item = list(item)
                    item[1] = 0
                    item = tuple(item)
                filtered_data.append(item)
    return filtered_data
def test_filter_digitsXX(dataset, digits=(0, 1)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            filtered_data.append(item)
    filtered_data = filtered_data[0:64 * 29]
    return filtered_data
def test_filter_digitsXY(dataset, digits=(2, 3)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            listitem = list(item)
            if item[1]==3:
                item = list(item)
                item[1] = 1
                item = tuple(item)
            else:
                item = list(item)
                item[1] = 0
                item = tuple(item)
            filtered_data.append(item)
    filtered_data = filtered_data[0:64 * 29]
    return filtered_data
def test_filter_digitsYX(dataset, digits=(4, 5)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            if item[1] in digits:
                if item[1] == 5:
                    item = list(item)
                    item[1] = 1
                    item = tuple(item)
                else:
                    item = list(item)
                    item[1] = 0
                    item = tuple(item)
                filtered_data.append(item)
    filtered_data = filtered_data[0:64 * 29]
    return filtered_data
def test_filter_digitsYY(dataset, digits=(6, 7)):
    filtered_data = []
    for item in dataset:
        if item[1] in digits:
            if item[1] in digits:
                if item[1] == 7:
                    item = list(item)
                    item[1] = 1
                    item = tuple(item)
                else:
                    item = list(item)
                    item[1] = 0
                    item = tuple(item)
                filtered_data.append(item)
    filtered_data=filtered_data[0:64*29]
    return filtered_data
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Resize((IMG_SIZE,IMG_SIZE))])
                                # transforms.Normalize((0.1307,), (0.3081,))

train_dataset = torchvision.datasets.MNIST("D:\pythonProject\ONN网络\\4个通道复用/data", train=True, transform=transform, download=False)
test_dataset = torchvision.datasets.MNIST("D:\pythonProject\ONN网络\\4个通道复用/data", train=False, transform=transform, download=False)
train_filteredXX = filter_digitsXX(train_dataset)
test_filteredXX  = test_filter_digitsXX(test_dataset)
train_filteredXY = filter_digitsXY(train_dataset)
test_filteredXY  = test_filter_digitsXY(test_dataset)
train_filteredYX = filter_digitsYX(train_dataset)
test_filteredYX  = test_filter_digitsYX(test_dataset)
train_filteredYY = filter_digitsYY(train_dataset)
test_filteredYY  = test_filter_digitsYY(test_dataset)
train_dataloaderXX = torch.utils.data.DataLoader(dataset=train_filteredXX, batch_size=batch_size, shuffle=True)
test_dataloaderXX = torch.utils.data.DataLoader(dataset=test_filteredXX, batch_size=batch_size, shuffle=False)
train_dataloaderXY = torch.utils.data.DataLoader(dataset=train_filteredXY, batch_size=batch_size, shuffle=True)
test_dataloaderXY = torch.utils.data.DataLoader(dataset=test_filteredXY, batch_size=batch_size, shuffle=False)
train_dataloaderYX = torch.utils.data.DataLoader(dataset=train_filteredYX, batch_size=batch_size, shuffle=True)
test_dataloaderYX = torch.utils.data.DataLoader(dataset=test_filteredYX, batch_size=batch_size, shuffle=False)
train_dataloaderYY = torch.utils.data.DataLoader(dataset=train_filteredYY, batch_size=batch_size, shuffle=True)
test_dataloaderYY = torch.utils.data.DataLoader(dataset=test_filteredYY, batch_size=batch_size, shuffle=False)

#print(len(test_dataloaderXX),len(test_dataloaderXY),len(test_dataloaderYX),len(test_dataloaderYY))

def generate_det(length,width,start_x,start_y,cycle,N_det):
    p = []
    for i in range(len(N_det)):
        for j in range(N_det[i]):
         left = start_x+j*(cycle+length)
         right = left+length
         up = start_y[i]
         down = start_y[i]+width
         p.append((up,down,left,right))
    return list(p)
monitor8 = generate_det(10,10,10,[4,20,45,65],20,[2,2,2,2])
def monitor_region(Int):
    detectors_list = []
    full_Int = Int.sum(dim=(2,3))
    #print(full_Int.shape)  torch.Size([64, 4])
    #print(type(monitor8),type(index))
    for det_x0, det_x1, det_y0, det_y1 in monitor8: # 计算各个探测器区间内的光强占比
        detectors_list.append((Int[:,:, det_x0 : det_x1, det_y0 : det_y1].sum(dim=(2, 3))/full_Int).unsqueeze(-1))
    # print((Int[:,:, det_x0 : det_x1, det_y0 : det_y1].sum(dim=(2, 3))/full_Int).shape,len(detectors_list))
    # torch.Size([64, 4])  8
    return torch.cat(detectors_list, dim = 2)
labels_image_tensorsXX=torch.zeros((2,N_pixels,N_pixels), device = device, dtype = torch.double)
labels_image_tensorsXY=torch.zeros((2,N_pixels,N_pixels), device = device, dtype = torch.double)
labels_image_tensorsYX=torch.zeros((2,N_pixels,N_pixels), device = device, dtype = torch.double)
labels_image_tensorsYY=torch.zeros((2,N_pixels,N_pixels), device = device, dtype = torch.double)
for ind, pos in enumerate(monitor8):
    pos_l, pos_r, pos_u, pos_d = pos
    if int in (0,1):
        labels_image_tensorsXX[ind, pos_l:pos_r, pos_u:pos_d] = 1
        labels_image_tensorsXX[ind] = labels_image_tensorsXX[ind]/labels_image_tensorsXX[ind].sum()
    if int in (2, 3):
        labels_image_tensorsXY[ind, pos_l:pos_r, pos_u:pos_d] = 1
        labels_image_tensorsXY[ind] = labels_image_tensorsXY[ind] / labels_image_tensorsXY[ind].sum()
    if int in (4, 5):
        labels_image_tensorsYX[ind, pos_l:pos_r, pos_u:pos_d] = 1
        labels_image_tensorsYX[ind] = labels_image_tensorsYX[ind] / labels_image_tensorsYX[ind].sum()
    if int in (6, 7):
        labels_image_tensorsYY[ind, pos_l:pos_r, pos_u:pos_d] = 1
        labels_image_tensorsYY[ind] = labels_image_tensorsYY[ind] / labels_image_tensorsYY[ind].sum()
class Equivalent_Layer(torch.nn.Module):
    def __init__(self, λ=532e-9, N_pixels=80,pixel_size=400e-9, distance=torch.tensor([0.002])):
        super(Equivalent_Layer, self).__init__()  # 初始化父类
        fx = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fy = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fxx, fyy = np.meshgrid(fx, fy)  # 拉网格，每个网格坐标点为空间频率各分量。

        argument = (2 * np.pi) ** 2 * ((1. / λ) ** 2 - fxx ** 2 - fyy ** 2)
        # 计算传播场或倏逝场的模式kz，传播场kz为实数，倏逝场kz为复数
        tmp = np.sqrt(np.abs(argument))
        self.distance = distance
        self.kz = torch.tensor(np.where(argument >= 0, tmp, 1j * tmp)).to(device)

    def forward(self, E):
        fft_c = torch.fft.fft2(E)  # 对电场E进行二维傅里叶变换
        c = torch.fft.fftshift(fft_c)
        phase = torch.exp(1j * self.kz * self.distance).to(device)
        angular_spectrum = torch.fft.ifft2(torch.fft.ifftshift(c * phase))  # 卷积后逆变换得到响应的角谱
        return angular_spectrum
class Diffractive_Layer(torch.nn.Module):
    def __init__(self, λ=532e-9, N_pixels=80,pixel_size=400e-9, distance=torch.tensor([0.002])):
        super(Diffractive_Layer, self).__init__()  # 初始化父类
        fx = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fy = np.fft.fftshift(np.fft.fftfreq(N_pixels, d=pixel_size))
        fxx, fyy = np.meshgrid(fx, fy)  # 拉网格，每个网格坐标点为空间频率各分量。

        argument = (2 * np.pi) ** 2 * ((1. / λ) ** 2 - fxx ** 2 - fyy ** 2)
        # 计算传播场或倏逝场的模式kz，传播场kz为实数，倏逝场kz为复数
        tmp = np.sqrt(np.abs(argument))
        self.distance = distance
        self.kz = torch.tensor(np.where(argument >= 0, tmp, 1j * tmp)).to(device)

    def forward(self, E):
        fft_c = torch.fft.fft2(E)  # 对电场E进行二维傅里叶变换
        c = torch.fft.fftshift(fft_c)
        phase = torch.exp(1j * self.kz * self.distance).to(device)
        angular_spectrum = torch.fft.ifft2(torch.fft.ifftshift(c * phase))  # 卷积后逆变换得到响应的角谱
        return angular_spectrum

def pulse_function(x_2, y_2, z=150e-6, wavelength=940e-9):
    # Convert nm to m for calculations
    x_2 = x_2 * 1e-9
    y_2 = y_2 * 1e-9
    x_1 = torch.arange(0, 500e-9*80, 500e-9)
    y_1 = torch.arange(0, 500e-9*80, 500e-9)
    i = 1j
    f = torch.zeros((len(x_1), len(y_1)), dtype=torch.cfloat)
    for idx_x, val_x in enumerate(x_1):
        for idx_y, val_y in enumerate(y_1):
            r = torch.sqrt(((x_2 - val_x)**2 + (y_2 - val_y)**2 + z**2)*10e+6)*10e-6
            k = 2 * np.pi / wavelength
            temp = (1/(2 * np.pi)) * ((i*k*r)/r) * (z/r) * ((1/r) - i * (2 * np.pi / wavelength))
            f[idx_x,idx_y] = temp
    return f

def phase_function(phi1,phi2,theta):
    J11, J12, J21, J22 = (torch.zeros((80, 80), dtype=torch.cfloat), torch.zeros((80, 80), dtype=torch.cfloat),
                          torch.zeros((80, 80), dtype=torch.cfloat), torch.zeros((80, 80), dtype=torch.cfloat))
    J11_1 = torch.cos(theta[0]) ** 2 * torch.exp(1j * phi1[0]) + torch.sin(
        theta[0]) ** 2 * torch.exp(1j * phi1[1])
    J12_1 = torch.sin(theta[0]) * torch.cos(theta[0]) * (
                torch.exp(1j * phi1[1]) - torch.exp(1j * phi1[0]))
    J21_1= torch.sin(theta[0]) * torch.cos(theta[0]) * (
                torch.exp(1j * phi1[0]) - torch.exp(1j * phi1[1]))
    J22_1 = torch.cos(theta[0]) ** 2 * torch.exp(1j * phi1[1]) + torch.sin(
        theta[0]) ** 2 * torch.exp(1j * phi1[0])
    J11_2 = torch.cos(theta[1]) ** 2 * torch.exp(1j * phi2[0]) + torch.sin(
        theta[1]) ** 2 * torch.exp(1j * phi2[1])
    J12_2 = torch.sin(theta[1]) * torch.cos(theta[1]) * (
            torch.exp(1j * phi2[1]) - torch.exp(1j * phi2[0]))
    J21_2 = torch.sin(theta[1]) * torch.cos(theta[1]) * (
            torch.exp(1j * phi2[1]) - torch.exp(1j * phi2[0]))
    J22_2 = torch.cos(theta[1]) ** 2 * torch.exp(1j * phi2[1]) + torch.sin(
        theta[1]) ** 2 * torch.exp(1j * phi2[0])
    for i in range(80):
        for j in range(80):
                pulse=pulse_function(i,j).to(device)
                J11[i, j] = J11_2[i,j]*torch.sum((J11_1*pulse*500e-9*500e-9))+J12_2[i,j]*torch.sum(
                    (J21_1*pulse*500e-9*500e-9))
                J12[i, j] = J11_2[i, j] * torch.sum((J12_1 * pulse * 500e-9 * 500e-9)) + J12_2[i, j] * torch.sum(
                    (J21_1 * pulse* 500e-9 * 500e-9))
                J21[i, j] = J21_2[i, j] * torch.sum((J11_1 * pulse * 500e-9 * 500e-9)) + J22_2[i, j] * torch.sum(
                    (J22_1 * pulse * 500e-9 * 500e-9))
                J22[i, j] = J21_2[i, j] * torch.sum((J12_1 * pulse * 500e-9 * 500e-9)) + J22_2[i, j] * torch.sum(
                    (J22_1 * pulse * 500e-9 * 500e-9))
    return torch.cat((torch.angle(J11).unsqueeze(0), torch.angle(J12).unsqueeze(0),
                      torch.angle(J21).unsqueeze(0),torch.angle(J22).unsqueeze(0)))

class DNN(torch.nn.Module):
    def __init__(self, num_layers=2, wl=940e-9, N_pixels=80, pixel_size=500e-9,
                 distance=[]):

        super(DNN, self).__init__()
        self.phi1 = [torch.nn.Parameter((torch.from_numpy((np.random.random(size=(N_pixels, N_pixels))*2*np.pi).
                                                          astype('float32'))).to(device)) for _ in range(num_layers)]
        self.phi2 = [torch.nn.Parameter((torch.from_numpy((np.random.random(size=(N_pixels, N_pixels)) * 2 * np.pi).
                                                         astype('float32'))).to(device)) for _ in range(num_layers)]
        self.theta = [torch.nn.Parameter((torch.from_numpy((np.random.random(size=(N_pixels, N_pixels))* 2 * np.pi).
                                                         astype('float32'))).to(device)) for _ in range(num_layers)]
        for i in range(num_layers):
            self.register_parameter("phi1" + "_" + str(i), self.phi1[i])
            self.register_parameter("phi2" + "_" + str(i), self.phi2[i])
        for i in range(num_layers-1):
            self.register_parameter("theta" + "_" + str(i), self.theta[i])
        self.Equivalent_Layer = Equivalent_Layer(wl, N_pixels, pixel_size, distance)
        self.last_diffractive_layer = Diffractive_Layer(wl, N_pixels, pixel_size, distance)
        self.sofmax = torch.nn.Softmax(dim=-1)

    # 计算多层衍射前向传播
    def forward(self, image):
        phase1 = phase_function(self.phi1, self.phi2, self.theta) #等效层的相位
        temp = self.Equivalent_Layer(image)
        E=temp*torch.exp(1j * phase1)
        E = self.Equivalent_Layer(E)
        phase2 = torch.cat((self.phi1[2].unsqueeze(0),self.phi2[2].unsqueeze(0),
                            self.phi1[2].unsqueeze(0),self.phi2[2].unsqueeze(0)),dim=0)
        E = E*torch.exp(1j*phase2)
        E = self.last_diffractive_layer(E)
        Int = torch.abs(E) ** 2
        output = monitor_region(Int)
        return output, Int[:,0],Int[:,1],Int[:,2],Int[:,3]

def train(model, loss_function, optimizer, trainloader,testloader, epochs=10, device=device):
    train_loss_hist = []
    test_loss_hist = []
    train_acc_hist = []
    test_acc_hist = []
    best_acc = 0
    for epoch in range(epochs):
        ep_loss = 0
        model.train()
        correct1 = 0
        total1 = 0
        # 加载进度条
        for loader in tqdm(trainloader):
            imagesXX,imagesXY,imagesYX,imagesYY=loader[0][0].squeeze().to(device),loader[1][0].squeeze().to(device),loader[2][0].squeeze().to(device),loader[3][0].squeeze().to(device)
            labelsXX,labelsXY,labelsYX,labelsYY=loader[0][1].to(device),loader[1][1].to(device),loader[2][1].to(device),loader[3][1].to(device)
            if labelsYX.size(0) < 64:  # 补齐
                labelsYX = torch.cat((labelsYX, labelsYX[0].unsqueeze(0)), dim=0)
                imagesYX = torch.cat((imagesYX, imagesYX[0, :, :].unsqueeze(0)), dim=0)
            det_labelsXX = F.one_hot(labelsXX, num_classes=8).to(dtype=torch.float64)
            det_labelsXY = F.one_hot(labelsXY+2, num_classes=8).to(dtype=torch.float64)
            det_labelsYX = F.one_hot(labelsYX+4, num_classes=8).to(dtype=torch.float64)
            det_labelsYY = F.one_hot(labelsYY+6, num_classes=8).to(dtype=torch.float64)
            det_labels = torch.cat((det_labelsXX,det_labelsXY,det_labelsYX,det_labelsYY),0)
            # 梯度清零
            optimizer.zero_grad()

            images=torch.cat((imagesXX.unsqueeze(1),imagesXY.unsqueeze(1),imagesYX.unsqueeze(1),
                              imagesYY.unsqueeze(1)),dim=1)
            out_label, out_imgXX,out_imgXY,out_imgYX,out_imgYY = model(images)
            out_labels=torch.cat((out_label[:,0].squeeze(1),out_label[:,1].squeeze(1),
                                  out_label[:,2].squeeze(1),out_label[:,3].squeeze(1)),dim=0)
            _, predicted = torch.max(out_labels.data, 1)
            _, last_labels = torch.max(det_labels.data, 1)
            #print(out_label.shape, predicted.shape) torch.Size([64, 4, 8]) torch.Size([64, 4])
            correct1 = correct1+(predicted == last_labels).sum().item()
            total1=total1+det_labels.size(0) # 得到一个batch的标签总数
            full_int_imgXX = out_imgXX.sum(axis=(1, 2))
            # print((out_img / full_int_img[:, None, None]).shape,det_labels.shape)
            #loss = loss_function(out_img / full_int_img[:, None, None], det_labels)  # 光强分布归一化后送入损失函数（与完美探测结果进行比较）
            loss1=0
            for index in range(out_imgXX.shape[0]):
                img = out_imgXX[index] * labels_image_tensorsXX[labelsXX[index]]
                loss1 = loss1 + loss_function(img, out_imgXX[index])
                #print(loss)
            for index in range(out_imgXY.shape[0]):
                img = out_imgXY[index] * labels_image_tensorsXY[labelsXY[index]]
                loss1 = loss1 + loss_function(img, out_imgXY[index])
            for index in range(out_imgYX.shape[0]):
                img = out_imgYX[index] * labels_image_tensorsYX[labelsYX[index]]
                loss1 = loss1 + loss_function(img, out_imgYX[index])
            for index in range(out_imgYY.shape[0]):
                img = out_imgYY[index] * labels_image_tensorsYY[labelsYY[index]]
                loss1 = loss1 + loss_function(img, out_imgYY[index])
            #loss1 = loss_function(out_labelXX, det_labelsXX)+loss_function(out_labelXY, det_labelsXY)+loss_function(out_labelYX, det_labelsYX)+loss_function(out_labelYY, det_labelsYY)#(64,10)
            #out_label=torch.cat((out_labelXX,out_labelXY,out_labelYX,out_labelYY),0)
            loss2 = loss_function(out_labels, det_labels*0.01)
            #print(loss1*0.000001,loss2)
            loss=loss1*0.000001+loss2
            loss.backward(retain_graph=True)  # 反向传播
            optimizer.step()
            ep_loss += loss.item()  # 更新本次epoch的损失
        # train_loss_hist.append(ep_loss / len(trainloader))  # 计算平均损失
        print(total1)
        train_acc_hist.append(correct1 / total1)  # 计算准确率
        ep_loss = 0
        model.eval()
        correct2 = 0
        total2 = 0
        with torch.no_grad():  # 停止梯度更新
            for loader in tqdm(testloader):
                imagesXX, imagesXY, imagesYX, imagesYY = loader[0][0].squeeze().to(device), loader[1][0].squeeze().to(
                    device), loader[2][0].squeeze().to(device), loader[3][0].squeeze().to(device)
                labelsXX, labelsXY, labelsYX, labelsYY = loader[0][1].to(device), loader[1][1].to(device), loader[2][
                    1].to(device), loader[3][1].to(device)
                images = torch.cat(
                    (imagesXX.unsqueeze(1), imagesXY.unsqueeze(1), imagesYX.unsqueeze(1),
                     imagesYY.unsqueeze(1)), dim=1)
                det_labelsXX = F.one_hot(labelsXX, num_classes=8).to(dtype=torch.float64)
                det_labelsXY = F.one_hot(labelsXY+2, num_classes=8).to(dtype=torch.float64)
                det_labelsYX = F.one_hot(labelsYX+4, num_classes=8).to(dtype=torch.float64)
                det_labelsYY = F.one_hot(labelsYY+6, num_classes=8).to(dtype=torch.float64)
                det_labels = torch.cat((det_labelsXX,det_labelsXY,det_labelsYX,det_labelsYY),0)
                out_label, out_imgXX,out_imgXY,out_imgYX,out_imgYY = model(images)  # 得到预测各个探测器上的光强分布以及探测层光强分布

                out_labels=torch.cat((out_label[:,0].squeeze(1),out_label[:,1].squeeze(1),
                                      out_label[:,2].squeeze(1),out_label[:,3].squeeze(1)),dim=0)
                _, predicted = torch.max(out_labels.data, 1)
                _, last_labels = torch.max(det_labels.data, 1)
                correct2 = correct2 + (predicted == last_labels).sum().item()
                total2 = total2+ labelsXX.size(0) + labelsXY.size(0) + labelsYX.size(0) + labelsYY.size(
                    0)
                loss = loss_function(out_labels, det_labels)
                ep_loss += loss.item()  # 更新本次epoch的损失
        # test_loss_hist.append(ep_loss / len(testloader))
        test_acc_hist.append(correct2 / total2)
        # 如果最后一次训练的准确率大于之前最好的准确率，则将最后一次的模型保存为最佳模型。
        # if test_acc_hist[-1] > best_acc:
        #     best_model = copy.deepcopy(model)
        # print(f"Epoch={epoch} train loss={train_loss_hist[epoch]:.4}, test loss={test_loss_hist[epoch]:.4}")
        print(f"train acc={train_acc_hist[epoch]:.4}, test acc={test_acc_hist[epoch]:.4}")
        print("-----------------------")

    return  train_loss_hist, train_acc_hist, test_loss_hist, test_acc_hist

wl = 940e-9
pixel_size = 500e-9
# 定义模型，损失函数和优化器
model = DNN( num_layers =3, wl = wl, pixel_size = pixel_size, distance = 150e-6).to(device)#20um
criterion = torch.nn.MSELoss(reduction='sum').to(device)
#criterion = torch.nn.CrossEntropyLoss(reduction='sum').to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.02)
train_dataloader=zip(train_dataloaderXX,train_dataloaderXY,train_dataloaderYX,train_dataloaderYY)
test_dataloader=zip(test_dataloaderXX,test_dataloaderXY,test_dataloaderYX,test_dataloaderYY)
train_loss_hist, train_acc_hist,test_loss_hist, test_acc_hist= train(model,
                          criterion,optimizer, train_dataloader,test_dataloader, epochs = 4,  device = device)
